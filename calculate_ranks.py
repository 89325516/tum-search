import pandas as pd
import json
import visual_rank_engine  # è°ƒç”¨ä½ å†™çš„ Rust åº“
import os

def run_pagerank():
    # 1. è¯»å–æ•°æ®
    try:
        edges_df = pd.read_csv('mock_data/edges.csv')
        with open('mock_data/tum_content.json', 'r') as f:
            content_data = json.load(f)
    except FileNotFoundError:
        print("âŒ Data file not found, please check mock_data folder")
        return

    # 2. å‡†å¤‡å›¾æ•°æ® (Source -> Target)
    # Rust å¼•æ“éœ€è¦ [(src, dst)] æ ¼å¼çš„åˆ—è¡¨
    edges = list(zip(edges_df['source_id'], edges_df['target_id']))

    # è·å–æ€»èŠ‚ç‚¹æ•° (å‡è®¾ ID æ˜¯è¿ç»­çš„ï¼Œå–æœ€å¤§ID + 1)
    max_id = max([x['id'] for x in content_data])
    num_nodes = max_id + 1

    # 3. æ¨¡æ‹Ÿâ€œæœ€åäº¤äº’æ—¶é—´â€ (ç”¨äºæ—¶é—´è¡°å‡ [cite: 63])
    # æˆ‘ä»¬ä» json é‡Œæå– timestamp_hours_ago
    # åˆ›å»ºä¸€ä¸ªåˆ—è¡¨ï¼Œç´¢å¼•æ˜¯ IDï¼Œå€¼æ˜¯ hours_ago
    last_interactions = [0.0] * num_nodes
    for item in content_data:
        last_interactions[item['id']] = item.get('timestamp_hours_ago', 24.0)

    print(f"ğŸš€ Calling Rust Engine to calculate Temporal PageRank for {num_nodes} nodes...")

    # 4. è°ƒç”¨ Rust å‡½æ•° [cite: 128]
    # å‚æ•°: num_nodes, edges, timestamps, damping(é˜»å°¼ç³»æ•°), decay(è¡°å‡ç³»æ•°), iterations
    scores = visual_rank_engine.calculate_temporal_pagerank(
        num_nodes,
        edges,
        last_interactions,
        0.85,  # Damping factor
        0.01,  # Time decay lambda
        50     # Iterations
    )

    # 5. ä¿å­˜ç»“æœ
    # æˆ‘ä»¬æŠŠåˆ†æ•°å­˜æˆå­—å…¸: {id: score}
    rank_dict = {i: score for i, score in enumerate(scores) if score > 0}

    with open('mock_data/pagerank_scores.json', 'w') as f:
        json.dump(rank_dict, f)

    print(f"âœ… Calculation complete! Scores saved to mock_data/pagerank_scores.json")
    # æ‰“å°å‰5åçœ‹çœ‹
    top_5 = sorted(rank_dict.items(), key=lambda x: x[1], reverse=True)[:5]
    print("ğŸ† Top 5 Authoritative Page IDs:", top_5)

if __name__ == "__main__":
    run_pagerank()