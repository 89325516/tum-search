import pickle
import torch
import numpy as np
import requests
import uuid
from transformers import CLIPProcessor, CLIPModel
from PIL import Image

# ================= é…ç½®åŒº =================
import os

# ä¿®æ”¹å‰ï¼š
# QDRANT_URL = "https://..."
# QDRANT_API_KEY = "ey..."

# ä¿®æ”¹åï¼š
QDRANT_URL = os.getenv("QDRANT_URL")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")

COLLECTION_NAME = "tum_data"
# =========================================

# 1. åŠ è½½èµ„æº (æ¨¡å‹ + é”šç‚¹)
print("âš™ï¸Initializing Ingestion Pipeline...")
clip_model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

# åŠ è½½â€œå…ƒè€é™¢â€æ•°æ®
try:
    with open('mock_data/anchors.pkl', 'rb') as f:
        ANCHORS = pickle.load(f)
    print(f"Loaded {len(ANCHORS)} anchor data points.")
except FileNotFoundError:
    print("âŒ Error: anchors.pkl not found. Please run Step 1 script first.")
    exit()


# --- æ ¸å¿ƒç®—æ³•ï¼šåŸºäºæŠ•å½±çš„å®æ—¶æ‰“åˆ† ---
def calculate_projected_score(target_vector):
    """
    è®¡ç®—å…¬å¼: Score(x) = Sum( Sim(x, anchor_i) * PR(anchor_i) )
    """
    scores = []
    # 1. è®¡ç®—ä¸æ‰€æœ‰é”šç‚¹çš„ç›¸ä¼¼åº¦
    for anchor in ANCHORS:
        # Cosine Similarity
        sim = np.dot(target_vector, anchor['vector'])
        if sim > 0:  # åªè€ƒè™‘æ­£ç›¸å…³
            scores.append({
                "sim": sim,
                "anchor_pr": anchor['pr_score']
            })

    # 2. æ’åºï¼Œå– Top 5 ç›¸ä¼¼çš„é”šç‚¹
    scores.sort(key=lambda x: x['sim'], reverse=True)
    top_k = scores[:5]

    # 3. åŠ æƒæ±‚å’Œ
    final_score = 0.0
    for item in top_k:
        final_score += item['sim'] * item['anchor_pr']

    # è½¬æ¢ä¸º Python float
    return float(final_score)


# --- å‘é‡åŒ–å·¥å…· ---
def get_clip_embedding(text=None, image_path=None):
    inputs = None
    if text:
        # åŠ å…¥ truncation é˜²æ­¢è¿‡é•¿æŠ¥é”™
        inputs = clip_processor(
            text=[text],
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=77
        )
        feat = clip_model.get_text_features(**inputs)
    elif image_path:
        try:
            image = Image.open(image_path).convert("RGB")
            inputs = clip_processor(images=image, return_tensors="pt")
            feat = clip_model.get_image_features(**inputs)
        except Exception as e:
            print(f"âŒğŸŒŒImage read failed: {e}")
            return None

    if inputs is not None:
        feat = feat / feat.norm(p=2, dim=-1, keepdim=True)
        return feat[0].detach().numpy()
    return None


# --- ä¸Šä¼ å·¥å…· (REST API) ---
def upload_to_qdrant(points):
    base_url = QDRANT_URL.rstrip('/')
    url = f"{base_url}/collections/{COLLECTION_NAME}/points?wait=true"

    headers = {
        "api-key": QDRANT_API_KEY,
        "Content-Type": "application/json"
    }

    # æ„é€  payload
    batch_points = []
    for p in points:
        # âš ï¸ å…³é”®ä¿®æ­£ï¼šå¯¹äº named vectorsï¼Œç›´æ¥ä½¿ç”¨ { "name": [vector] } çš„å­—å…¸æ ¼å¼
        # ä¸éœ€è¦åµŒå¥— "name": "clip", "vector": ...

        vector_struct = {}
        if p['vector_name'] == 'clip':
            vector_struct['clip'] = p['vector'].tolist()
            # å¦‚æœä¹‹å‰å®šä¹‰äº† 'dino' ä¸”æ˜¯å¿…é¡»çš„ï¼Œå¯ä»¥åœ¨è¿™é‡Œè¡¥é›¶ï¼Œä½†é€šå¸¸ sparse ä¹Ÿæ˜¯å…è®¸çš„
            # ä¸ºäº†å…¼å®¹æ€§ï¼Œæˆ‘ä»¬åªä¼  clip

        batch_points.append({
            "id": str(uuid.uuid4()),
            "vector": vector_struct,  # <--- ä¿®æ­£åçš„ç»“æ„
            "payload": p['payload']
        })

    try:
        resp = requests.put(url, headers=headers, json={"points": batch_points})

        if resp.status_code != 200:
            print(f"âŒ Server returned error: {resp.status_code}")
            print(resp.text)
        else:
            print(f"âœ… Successfully ingested {len(points)} items! (With real-time scoring)")

    except Exception as e:
        print(f"âŒ Ingestion request failed: {e}")


# --- ä¸»å…¥å£å‡½æ•°ï¼šæ·»åŠ æ–°å†…å®¹ ---
def add_new_content(url, text_content=None, image_path=None):
    points_to_upload = []

    # 1. å¤„ç†æ–‡æœ¬éƒ¨åˆ†
    if text_content:
        print(f"âš™ï¸Processing text: {text_content[:30]}...")
        vec = get_clip_embedding(text=text_content)
        if vec is not None:
            pr_score = calculate_projected_score(vec)

            points_to_upload.append({
                "vector": vec,
                "vector_name": "clip",  # æ ‡è®°è¿™æ˜¯ CLIP å‘é‡
                "payload": {
                    "url": url,
                    "type": "text",
                    "content_preview": text_content[:100],
                    "pr_score": pr_score,
                    "is_new": True
                }
            })
            print(f"   -> âœ…Text score: {pr_score:.6f}")

    # 2. å¤„ç†å›¾åƒéƒ¨åˆ†
    if image_path:
        print(f"âš™ï¸Processing image: {image_path}...")
        vec = get_clip_embedding(image_path=image_path)
        if vec is not None:
            pr_score = calculate_projected_score(vec)
            # æ³¨æ„ï¼šå›¾ç‰‡è¿™é‡Œæˆ‘ä»¬ä¹Ÿæš‚æ—¶ä½œä¸º CLIP å‘é‡ä¸Šä¼ ï¼Œå› ä¸ºæˆ‘ä»¬çš„æœç´¢ä¸»è¦åŸºäºè¯­ä¹‰
            # å¦‚æœä½ æœ‰ä¸“é—¨çš„ DINO æœç´¢éœ€æ±‚ï¼Œéœ€è¦åœ¨è¿™é‡ŒåŒºåˆ†
            points_to_upload.append({
                "vector": vec,
                "vector_name": "clip",
                "payload": {
                    "url": url,
                    "type": "image",
                    "content_preview": "Image content",
                    "pr_score": pr_score,
                    "is_new": True
                }
            })
            print(f"   -> âœ…ğŸŒŒImage score: {pr_score:.6f}")

    # 3. æ‰§è¡Œä¸Šä¼ 
    if points_to_upload:
        upload_to_qdrant(points_to_upload)


# --- æµ‹è¯•ç”¨ä¾‹ ---
if __name__ == "__main__":
    print("-" * 50)
    print("âš™ï¸Simulating new data entering the system...")

    new_url = "https://google.com/search/pagerank_explained"
    new_text = "PageRank works by counting the number and quality of links to a page to determine a rough estimate of how important the website is."

    # è¿è¡Œ
    add_new_content(new_url, text_content=new_text)