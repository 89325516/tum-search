import json
import torch
import numpy as np
import random
import sys
import os
from dotenv import load_dotenv

load_dotenv()
from qdrant_client import QdrantClient

# Add root to path
sys.path.append(os.getcwd())
from consistency_engine import ConsistencyEngine

from transformers import CLIPProcessor, CLIPModel
from scipy.stats import rankdata

# ================= é…ç½®åŒº =================
# ğŸ”´ ä½ çš„çœŸå®é…ç½®
QDRANT_URL = os.getenv("QDRANT_URL")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")
SPACE_X = "tum_space_x"
# =========================================

print("ğŸ› ï¸Initializing Search Engine...")

# 1. è¿æ¥ Qdrant
print("ğŸ”—Connecting to Qdrant Database...")
client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)

# 2. åŠ è½½æœ¬åœ° CLIP (CPUæ¨¡å¼)
print("âš™ï¸Loading local CLIP model (CPU mode)...")
clip_model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

# 3. åˆå§‹åŒ–ä¸€è‡´æ€§å¼•æ“
consistency_engine = ConsistencyEngine()

# --- è¾…åŠ©å‡½æ•°ï¼šé«˜æ–¯ç§©å½’ä¸€åŒ– ---
def gauss_rank_norm(scores):
    if not scores: return []
    ranks = rankdata(scores, method='average')
    return (ranks / len(scores)).tolist()

# --- æ ¸å¿ƒæœç´¢å‡½æ•° ---
def search(query_text, top_k=10):
    print(f"\nğŸ” Searching for: '{query_text}' ...")

    # ---------------------------------------------------------
    # Layer 1: Vector Embedding (CLIP)
    # ---------------------------------------------------------
    inputs = clip_processor(text=[query_text], return_tensors="pt", padding=True)
    with torch.no_grad():
        query_vector = clip_model.get_text_features(**inputs)
        query_vector = query_vector / query_vector.norm(p=2, dim=-1, keepdim=True)
        query_vector = query_vector[0].numpy().tolist()

    # ---------------------------------------------------------
    # Layer 2: Qdrant Search (HNSW)
    # ---------------------------------------------------------
    # ç›´æ¥æŸ¥è¯¢ Space X (åŒ…å«æ‰€æœ‰å†…å®¹)
    try:
        hits = client.query_points(
            collection_name=SPACE_X,
            query=query_vector,
            using="clip",
            limit=top_k * 3  # å¤šå–ä¸€äº›ç”¨äºé‡æ’
        ).points
    except Exception as e:
        print(f"âŒ Qdrant search failed: {e}")
        return []

    # ---------------------------------------------------------
    # Layer 3: Fusion & Ranking & Safeguards
    # ---------------------------------------------------------
    results = []
    raw_sims = []
    raw_prs = []
    
    total_candidates = len(hits)

    for rank_idx, hit in enumerate(hits):
        hit_id = hit.id
        sim = hit.score
        payload = hit.payload

        # è·å–æƒå¨åº¦ (PageRank)
        pr = payload.get('pr_score', 0.0)

        # --- ç¬¬å››é“é˜²çº¿ï¼šä¸€è‡´æ€§æ ¡éªŒ (Consistency Check) ---
        # æ£€æŸ¥ CLIP æ’åä¸ DINO æ’åçš„å†²çª (Mock)
        is_consistent, conflict_loss = consistency_engine.check_consistency(
            query_text, payload, rank_idx, total_candidates
        )
        
        if not is_consistent:
            print(f"ğŸ›¡ï¸ [Circuit Breaker] Blocked ID {hit_id}: High Semantic-Visual Conflict (Loss: {conflict_loss:.2f})")
            continue

        raw_sims.append(sim)
        raw_prs.append(pr)

        results.append({
            "id": hit_id,
            "sim": sim,
            "pr": pr,
            "payload": payload,
            "conflict_loss": conflict_loss
        })

    # 4. å½’ä¸€åŒ–å¤„ç† (Gauss Rank)
    norm_sims = gauss_rank_norm(raw_sims)
    norm_prs = gauss_rank_norm(raw_prs)

    final_ranked = []

    # æƒé‡è®¾å®š
    w_sim = 0.7
    w_pr = 0.3

    for i, item in enumerate(results):
        # æœ€ç»ˆæ‰“åˆ†å…¬å¼
        final_score = w_sim * norm_sims[i] + w_pr * norm_prs[i]

        # è§£æå†…å®¹
        p = item['payload']
        content_type = p.get('type', 'unknown')
        url = p.get('url', '#')
        preview = p.get('content_preview', 'No preview')
        if isinstance(preview, list): preview = preview[0]

        final_ranked.append({
            "score": final_score,
            "type": content_type,
            "url": url,
            "content": preview,
            "id": item['id'],
            "is_exploration": False
        })

    # 5. æ’åº
    final_ranked.sort(key=lambda x: x['score'], reverse=True)
    
    # --- ç¬¬ä¸‰é“é˜²çº¿ (B)ï¼šæ¢ç´¢çº¢åˆ© (Exploration Bonus) ---
    # éšæœºæ’å…¥æ–°å†…å®¹ (Bandit ç®—æ³•)
    if random.random() < 0.05: # 5% æ¦‚ç‡è§¦å‘
        print("ğŸ² [Exploration] Triggering exploration mechanism, injecting new content...")
        # è¿™é‡Œç®€å•æ¨¡æ‹Ÿï¼šéšæœºå–ä¸€ä¸ªä½åˆ†ç»“æœæå‡åˆ°ç¬¬ 2 å
        if len(final_ranked) > 5:
            lucky_idx = random.randint(5, len(final_ranked)-1)
            lucky_item = final_ranked.pop(lucky_idx)
            lucky_item['is_exploration'] = True
            lucky_item['score'] += 0.5 # å¼ºè¡ŒåŠ åˆ†
            final_ranked.insert(1, lucky_item) # æ’å…¥åˆ°ç¬¬äºŒä½

    return final_ranked[:top_k]


# --- ç»“æœå±•ç¤º ---
def display_results(results):
    print("\n" + "=" * 40)
    print("      SEARCH RESULTS (Top 5)      ")
    print("=" * 40)

    if not results:
        print("No results found.")
        return

    for i, res in enumerate(results[:5]):
        icon = "ğŸ“„"
        if res['type'] == 'image':
            icon = "ğŸ–¼ï¸"
        elif res['type'] == 'audio':
            icon = "ğŸµ"
            
        explore_tag = " [ğŸ² EXPLORE]" if res.get('is_exploration') else ""

        print(f"{i + 1}. {icon} [{res['type'].upper()}]{explore_tag} (Score: {res['score']:.4f})")
        print(f"   ğŸ”— URL: {res['url']}")
        content_str = str(res['content'])
        print(f"   ğŸ“ Content: {content_str[:100]}...")
        print("-" * 40)


# --- ä¸»ç¨‹åºå…¥å£ ---
if __name__ == "__main__":
    while True:
        q = input("\nè¯·è¾“å…¥æœç´¢å…³é”®è¯ (è¾“å…¥ 'exit' é€€å‡º): ")
        if q.lower() == 'exit': break

        results = search(q)
        display_results(results)