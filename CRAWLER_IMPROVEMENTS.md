# çˆ¬è™«ä¼˜åŒ–è¯´æ˜

## æ”¹è¿›ç‚¹

### 1. **å‘åå…¼å®¹æ€§** âœ…
- ä¿ç•™äº†åŸæœ‰çš„ `SmartCrawler` ç±»ï¼Œç¡®ä¿ç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹å³å¯å·¥ä½œ
- è¿”å›æ ¼å¼å®Œå…¨å…¼å®¹ï¼š`{"url": str, "texts": List[str], "images": List[str], "links": List[str]}`

### 2. **å¼‚æ­¥é«˜æ€§èƒ½çˆ¬è™«** âœ…
- æ–°å¢ `OptimizedCrawler` ç±»ï¼Œæ”¯æŒå¼‚æ­¥å¹¶å‘å¤„ç†
- ä½¿ç”¨ `aiohttp` æ›¿ä»£ `requests`ï¼Œæ€§èƒ½æå‡æ˜¾è‘—
- æ”¯æŒæ‰¹é‡URLå¤„ç†ï¼Œé€‚åˆé€’å½’çˆ¬å–åœºæ™¯

### 3. **æ€§èƒ½ä¼˜åŒ–** âœ…
- **å¹¶å‘æ§åˆ¶**ï¼šä½¿ç”¨ `Semaphore` é™åˆ¶å¹¶å‘æ•°ï¼Œé˜²æ­¢è¢«å°IP
- **çº¿ç¨‹æ± **ï¼šCPUå¯†é›†å‹çš„HTMLè§£æä»»åŠ¡æ”¾åˆ°çº¿ç¨‹æ± ï¼Œä¸é˜»å¡äº‹ä»¶å¾ªç¯
- **é¢„ç¼–è¯‘æ­£åˆ™**ï¼šæå‡æ­£åˆ™åŒ¹é…é€Ÿåº¦
- **æŒ‡æ•°é€€é¿**ï¼šé‡è¯•æ—¶ä½¿ç”¨æŒ‡æ•°é€€é¿ç­–ç•¥
- **è‡ªåŠ¨é‡å®šå‘**ï¼šæ­£ç¡®å¤„ç†HTTPé‡å®šå‘

### 4. **å†…å®¹æå–ä¼˜åŒ–** âœ…
- **æ›´æ™ºèƒ½çš„DOMæ¸…æ´—**ï¼šç§»é™¤æ›´å¤šå™ªå£°å…ƒç´ ï¼ˆcookieã€popupã€bannerç­‰ï¼‰
- **æ”¹è¿›çš„æ–‡æœ¬æå–**ï¼šä¼˜å…ˆæå–æ­£æ–‡æ ‡ç­¾ï¼ˆp, article, main, sectionç­‰ï¼‰
- **æ›´å¥½çš„å›¾ç‰‡æå–**ï¼šæ”¯æŒ `data-src` å’Œ `data-lazy-src` ç­‰æ‡’åŠ è½½å±æ€§
- **é“¾æ¥å»é‡**ï¼šä½¿ç”¨setè‡ªåŠ¨å»é‡ï¼Œä¿ç•™é¡ºåº

### 5. **é”™è¯¯å¤„ç†å¢å¼º** âœ…
- å®Œå–„çš„å¼‚å¸¸æ•è·å’Œæ—¥å¿—è®°å½•
- è¶…æ—¶å¤„ç†
- ç½‘ç»œé”™è¯¯é‡è¯•æœºåˆ¶
- ç¼–ç è‡ªåŠ¨æ£€æµ‹

### 6. **ä»£ç è´¨é‡** âœ…
- ç±»å‹æç¤º
- è¯¦ç»†çš„æ–‡æ¡£å­—ç¬¦ä¸²
- æ¨¡å—åŒ–è®¾è®¡
- èµ„æºæ¸…ç†ï¼ˆexecutorå…³é—­ï¼‰

## ä¸è¶³å’Œæ”¹è¿›å»ºè®®

### 1. **ç¼ºå°‘çš„åŠŸèƒ½**
- âŒ **robots.txt æ”¯æŒ**ï¼šæœªæ£€æŸ¥robots.txtï¼Œå¯èƒ½è¿åç½‘ç«™æ”¿ç­–
- âŒ **é€Ÿç‡é™åˆ¶**ï¼šè™½ç„¶æœ‰å¹¶å‘æ§åˆ¶ï¼Œä½†ç¼ºå°‘å…¨å±€é€Ÿç‡é™åˆ¶
- âŒ **JavaScriptæ¸²æŸ“**ï¼šæ— æ³•å¤„ç†éœ€è¦JSæ¸²æŸ“çš„SPAé¡µé¢
- âŒ **Cookie/Sessionç®¡ç†**ï¼šä¸æ”¯æŒéœ€è¦ç™»å½•çš„é¡µé¢
- âŒ **å†…å®¹å»é‡**ï¼šæœªæ£€æµ‹é‡å¤å†…å®¹ï¼ˆåŸºäºå†…å®¹hashï¼‰

### 2. **å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–çš„åœ°æ–¹**
- ğŸ”„ **ç¼“å­˜æœºåˆ¶**ï¼šå¯ä»¥æ·»åŠ URLç¼“å­˜ï¼Œé¿å…é‡å¤çˆ¬å–
- ğŸ”„ **å¢é‡çˆ¬å–**ï¼šæ”¯æŒåŸºäºETag/Last-Modifiedçš„å¢é‡æ›´æ–°
- ğŸ”„ **åˆ†å¸ƒå¼çˆ¬å–**ï¼šæ”¯æŒå¤šæœºå™¨ååŒçˆ¬å–
- ğŸ”„ **æ™ºèƒ½è°ƒåº¦**ï¼šæ ¹æ®ç½‘ç«™å“åº”é€Ÿåº¦åŠ¨æ€è°ƒæ•´å¹¶å‘æ•°

### 3. **å®‰å…¨æ€§**
- âš ï¸ **SSLéªŒè¯**ï¼šå½“å‰ `ssl=False`ï¼Œç”Ÿäº§ç¯å¢ƒåº”å¯ç”¨
- âš ï¸ **è¾“å…¥éªŒè¯**ï¼šURLè¾“å…¥éªŒè¯å¯ä»¥æ›´ä¸¥æ ¼
- âš ï¸ **èµ„æºé™åˆ¶**ï¼šç¼ºå°‘å†…å­˜å’Œç£ç›˜ä½¿ç”¨é™åˆ¶

## ä½¿ç”¨å»ºè®®

### åœºæ™¯1ï¼šå•URLçˆ¬å–ï¼ˆç°æœ‰ä»£ç ï¼‰
```python
from crawler import SmartCrawler

crawler = SmartCrawler()
result = crawler.parse("https://example.com")
# è¿”å›: {"url": ..., "texts": [...], "images": [...], "links": [...]}
```

### åœºæ™¯2ï¼šæ‰¹é‡URLçˆ¬å–ï¼ˆé«˜æ€§èƒ½ï¼‰
```python
from crawler import OptimizedCrawler
import asyncio

crawler = OptimizedCrawler(concurrency=5)
urls = ["https://example.com/page1", "https://example.com/page2"]
results = asyncio.run(crawler.run(urls))
```

### åœºæ™¯3ï¼šé€’å½’çˆ¬å–ä¼˜åŒ–ï¼ˆå»ºè®®ï¼‰
å¯ä»¥åœ¨ `system_manager.py` ä¸­ä½¿ç”¨ `OptimizedCrawler` æ¥åŠ é€Ÿé€’å½’çˆ¬å–ï¼š

```python
# åœ¨ SystemManager ä¸­
async def process_url_recursive_async(self, start_url, max_depth=1, callback=None):
    """ä½¿ç”¨å¼‚æ­¥çˆ¬è™«çš„é€’å½’çˆ¬å–"""
    from crawler import OptimizedCrawler
    
    async_crawler = OptimizedCrawler(concurrency=3)
    visited = set()
    queue = [(start_url, 0)]
    all_urls = []
    
    # æ”¶é›†æ‰€æœ‰URL
    while queue:
        current_url, depth = queue.pop(0)
        if current_url in visited or depth > max_depth:
            continue
        visited.add(current_url)
        all_urls.append(current_url)
        
        # è·å–é“¾æ¥ï¼ˆè¿™é‡Œç®€åŒ–ï¼Œå®é™…åº”è¯¥å…ˆçˆ¬å–è·å–é“¾æ¥ï¼‰
        # ...
    
    # æ‰¹é‡å¼‚æ­¥çˆ¬å–
    results = await async_crawler.run(all_urls)
    # å¤„ç†ç»“æœ...
```

## æ€§èƒ½å¯¹æ¯”

### æµ‹è¯•åœºæ™¯ï¼šçˆ¬å–3ä¸ªTUMé¡µé¢

**SmartCrawler (åŒæ­¥)**:
- æ—¶é—´ï¼š~3-5ç§’
- æ–¹å¼ï¼šä¸²è¡Œå¤„ç†

**OptimizedCrawler (å¼‚æ­¥, concurrency=3)**:
- æ—¶é—´ï¼š~1-2ç§’
- æ–¹å¼ï¼šå¹¶å‘å¤„ç†
- **æå‡ï¼š2-3å€**

## æ³¨æ„äº‹é¡¹

1. **ä¾èµ–å®‰è£…**ï¼š
   ```bash
   pip install aiohttp beautifulsoup4 lxml fake-useragent
   ```

2. **fake-useragent å¯é€‰**ï¼š
   - å¦‚æœæœªå®‰è£…ï¼Œä¼šä½¿ç”¨é»˜è®¤User-Agent
   - å»ºè®®å®‰è£…ä»¥è·å¾—æ›´å¥½çš„åçˆ¬è™«æ•ˆæœ

3. **lxml è§£æå™¨**ï¼š
   - æ¯”é»˜è®¤çš„html.parserå¿«å¾ˆå¤š
   - å¦‚æœæœªå®‰è£…ï¼ŒBeautifulSoupä¼šå›é€€åˆ°html.parser

4. **å¹¶å‘æ•°è®¾ç½®**ï¼š
   - å»ºè®®ï¼š3-5ï¼ˆå¯¹å•ä¸ªç½‘ç«™ï¼‰
   - æ‰¹é‡çˆ¬å–ï¼š5-10
   - æ³¨æ„ï¼šè¿‡é«˜å¯èƒ½è¢«å°IP

## æœªæ¥æ”¹è¿›æ–¹å‘

1. æ·»åŠ  `robots.txt` è§£æå’Œéµå®ˆ
2. å®ç°æ™ºèƒ½é€Ÿç‡é™åˆ¶ï¼ˆåŸºäºç½‘ç«™å“åº”ï¼‰
3. æ”¯æŒ Selenium/Playwright ç”¨äºJSæ¸²æŸ“
4. æ·»åŠ å†…å®¹å»é‡ï¼ˆåŸºäºhashï¼‰
5. å®ç°åˆ†å¸ƒå¼çˆ¬å–æ”¯æŒ
6. æ·»åŠ çˆ¬å–ç»Ÿè®¡å’Œç›‘æ§

