import json
import torch
import pickle
import numpy as np
from transformers import CLIPProcessor, CLIPModel

# ================= é…ç½® =================
# æˆ‘ä»¬åªé€‰æœ€æƒå¨çš„ 50 ä¸ªèŠ‚ç‚¹ä½œä¸ºé”šç‚¹
TOP_K_ANCHORS = 50
# =======================================

print("æ­£åœ¨æ„å»º'å…ƒè€é™¢' (Anchors Cache)...")

# 1. åŠ è½½ä¹‹å‰çš„è®¡ç®—ç»“æœ
try:
    with open('mock_data/pagerank_scores.json', 'r') as f:
        scores = json.load(f)
    with open('mock_data/tum_content.json', 'r') as f:
        content_list = json.load(f)
except FileNotFoundError:
    print("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ã€‚è¯·ç¡®ä¿ mock_data æ–‡ä»¶å¤¹ä¸‹æœ‰ pagerank_scores.json å’Œ tum_content.json")
    exit()

# å°†å†…å®¹è½¬ä¸ºå­—å…¸æ–¹ä¾¿æŸ¥æ‰¾
content_dict = {item['id']: item for item in content_list}

# 2. é€‰å‡ºåˆ†æ•°æœ€é«˜çš„ Top K
# æ³¨æ„ï¼šç¡®ä¿ key è½¬ä¸º int ä¸”åœ¨ content_dict ä¸­å­˜åœ¨
sorted_ids = sorted([int(k) for k in scores.keys()], key=lambda k: scores[str(k)], reverse=True)
valid_anchors_ids = [aid for aid in sorted_ids if aid in content_dict][:TOP_K_ANCHORS]

# 3. åŠ è½½ CLIP æ¨¡å‹ (CPUæ¨¡å¼)
print("æ­£åœ¨åŠ è½½ CLIP æ¨¡å‹...")
device = "cpu"
model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32").to(device)
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

anchors = []

print(f"æ­£åœ¨è®¡ç®— {len(valid_anchors_ids)} ä¸ªé”šç‚¹çš„å‘é‡æŒ‡çº¹...")

for aid in valid_anchors_ids:
    item = content_dict.get(aid)
    if not item: continue

    # æå–é”šç‚¹çš„æ ¸å¿ƒç‰¹å¾
    # å¦‚æœå†…å®¹æ˜¯çº¯æ–‡æœ¬ï¼Œç›´æ¥ç”¨ï¼›å¦‚æœæ˜¯å›¾ç‰‡ï¼Œè¿™é‡Œæš‚æ—¶ç”¨å›¾ç‰‡çš„æ–‡å­—æè¿°æ¥ä»£æ›¿é”šç‚¹ç‰¹å¾
    # (å› ä¸ºé”šç‚¹åº“éœ€è¦ç»Ÿä¸€çš„å‘é‡ç©ºé—´ï¼Œç”¨ Text Encoder ç”Ÿæˆé”šç‚¹æ˜¯æœ€ç¨³å¥çš„åŸºå‡†)
    text_content = item.get('content', item.get('content_desc', ''))

    # âš ï¸ ä¿®æ­£ç‚¹ï¼šåŠ å…¥ truncation=True å’Œ max_length=77
    inputs = processor(
        text=[text_content],
        return_tensors="pt",
        padding=True,
        truncation=True,  # <--- å…³é”®ä¿®å¤ï¼šå¼ºåˆ¶æˆªæ–­è¿‡é•¿çš„æ–‡æœ¬
        max_length=77  # <--- å…³é”®ä¿®å¤ï¼šé™åˆ¶æœ€å¤§é•¿åº¦ä¸º CLIP çš„ä¸Šé™
    )

    with torch.no_grad():
        emb = model.get_text_features(**inputs)
        emb = emb / emb.norm(p=2, dim=-1, keepdim=True)  # å½’ä¸€åŒ–

    anchors.append({
        "id": aid,
        "pr_score": scores[str(aid)],  # å®ƒçš„æƒå¨åˆ† (å®¶äº§)
        "vector": emb[0].numpy()  # å®ƒçš„é•¿ç›¸ (ç”¨äºå¯¹æ¯”)
    })

# 4. ä¿å­˜é”šç‚¹æ•°æ®åˆ°æœ¬åœ°
if anchors:
    with open('mock_data/anchors.pkl', 'wb') as f:
        pickle.dump(anchors, f)
    print(f"âœ… 'å…ƒè€é™¢'æ„å»ºå®Œæˆï¼å·²ä¿å­˜ {len(anchors)} ä¸ªé”šç‚¹è‡³ mock_data/anchors.pkl")
    print("ğŸ’¡ ä¸‹ä¸€æ­¥ï¼šè¯·è¿è¡Œ Step 2 (ingest_data.py) æ¥æµ‹è¯•æ–°æ•°æ®å…¥åº“å’Œå®æ—¶æ‰“åˆ†ã€‚")
else:
    print("âŒ è­¦å‘Šï¼šç”Ÿæˆçš„é”šç‚¹åˆ—è¡¨ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ pagerank_scores.json æ˜¯å¦æœ‰æ•°æ®ã€‚")