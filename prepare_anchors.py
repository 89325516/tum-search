import json
import torch
import pickle
import numpy as np
from transformers import CLIPProcessor, CLIPModel

# ================= é…ç½® =================
# æˆ‘ä»¬åªé€‰æœ€æƒå¨çš„ 50 ä¸ªèŠ‚ç‚¹ä½œä¸ºé”šç‚¹
TOP_K_ANCHORS = 50
# =======================================

print("âš™ï¸Building 'Anchors Cache'...")

# 1. åŠ è½½ä¹‹å‰çš„è®¡ç®—ç»“æœ
try:
    with open('mock_data/pagerank_scores.json', 'r') as f:
        scores = json.load(f)
    with open('mock_data/tum_content.json', 'r') as f:
        content_list = json.load(f)
except FileNotFoundError:
    print("âŒ Error: Data files not found. Please ensure pagerank_scores.json and tum_content.json exist in mock_data folder")
    exit()

# å°†å†…å®¹è½¬ä¸ºå­—å…¸æ–¹ä¾¿æŸ¥æ‰¾
content_dict = {item['id']: item for item in content_list}

# 2. é€‰å‡ºåˆ†æ•°æœ€é«˜çš„ Top K
# æ³¨æ„ï¼šç¡®ä¿ key è½¬ä¸º int ä¸”åœ¨ content_dict ä¸­å­˜åœ¨
sorted_ids = sorted([int(k) for k in scores.keys()], key=lambda k: scores[str(k)], reverse=True)
valid_anchors_ids = [aid for aid in sorted_ids if aid in content_dict][:TOP_K_ANCHORS]

# 3. åŠ è½½ CLIP æ¨¡å‹ (CPUæ¨¡å¼)
print("âš™ï¸Loading CLIP model...")
device = "cpu"
model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32").to(device)
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

anchors = []

print(f"ğŸ§®Calculating vector fingerprints for {len(valid_anchors_ids)} anchors...")

for aid in valid_anchors_ids:
    item = content_dict.get(aid)
    if not item: continue

    # æå–é”šç‚¹çš„æ ¸å¿ƒç‰¹å¾
    # å¦‚æœå†…å®¹æ˜¯çº¯æ–‡æœ¬ï¼Œç›´æ¥ç”¨ï¼›å¦‚æœæ˜¯å›¾ç‰‡ï¼Œè¿™é‡Œæš‚æ—¶ç”¨å›¾ç‰‡çš„æ–‡å­—æè¿°æ¥ä»£æ›¿é”šç‚¹ç‰¹å¾
    # (å› ä¸ºé”šç‚¹åº“éœ€è¦ç»Ÿä¸€çš„å‘é‡ç©ºé—´ï¼Œç”¨ Text Encoder ç”Ÿæˆé”šç‚¹æ˜¯æœ€ç¨³å¥çš„åŸºå‡†)
    text_content = item.get('content', item.get('content_desc', ''))

    # âš ï¸ ä¿®æ­£ç‚¹ï¼šåŠ å…¥ truncation=True å’Œ max_length=77
    inputs = processor(
        text=[text_content],
        return_tensors="pt",
        padding=True,
        truncation=True,  # <--- å…³é”®ä¿®å¤ï¼šå¼ºåˆ¶æˆªæ–­è¿‡é•¿çš„æ–‡æœ¬
        max_length=77  # <--- å…³é”®ä¿®å¤ï¼šé™åˆ¶æœ€å¤§é•¿åº¦ä¸º CLIP çš„ä¸Šé™
    )

    with torch.no_grad():
        emb = model.get_text_features(**inputs)
        emb = emb / emb.norm(p=2, dim=-1, keepdim=True)  # å½’ä¸€åŒ–

    anchors.append({
        "id": aid,
        "pr_score": scores[str(aid)],  # å®ƒçš„æƒå¨åˆ† (å®¶äº§)
        "vector": emb[0].numpy()  # å®ƒçš„é•¿ç›¸ (ç”¨äºå¯¹æ¯”)
    })

# 4. ä¿å­˜é”šç‚¹æ•°æ®åˆ°æœ¬åœ°
if anchors:
    with open('mock_data/anchors.pkl', 'wb') as f:
        pickle.dump(anchors, f)
    print(f"âœ… 'Anchors Cache' built successfully! Saved {len(anchors)} anchors to mock_data/anchors.pkl")
    print("ğŸ’¡ Next Step: Run Step 2 (ingest_data.py) to test new data ingestion and real-time scoring.")
else:
    print("âŒ Warning: Generated anchor list is empty, please check if pagerank_scores.json has data.")